{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分词 + 停用词筛选\n",
    "# jieba分词，将结果保存在seg.txt里面\n",
    "# seg_lst = []\n",
    "# for pdf in pdfs:\n",
    "#     with open(pdf,'r',encoding='utf8') as f:\n",
    "#         with open('data/segword/seg.txt','w', encoding='utf8') as segFile:\n",
    "#             for l in f:\n",
    "#                 l = l.strip()\n",
    "#                 reg = re.compile(\"[^\\u4e00-\\u9fa5]\")\n",
    "#                 l = re.sub(reg, '', l)\n",
    "#                 if l != '':\n",
    "#                     if l not in stopwords:\n",
    "#                         # seg_lst.append(list(pseg.cut(l)))\n",
    "#                         for p,flag in set(pseg.cut(l)):\n",
    "#                             segFile.write(str(p) + '\\t' + str(flag))\n",
    "#                             segFile.write('\\n')\n",
    "                        \n",
    "#         print('分词结果保存成功')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wc = {}\n",
    "# with open('data/segword/wc.txt','w', encoding='utf8') as wcFile:\n",
    "#     for l in seg_lst:\n",
    "#         for p in l:\n",
    "#             p = list(p)\n",
    "#             if wc.get(p[0]):\n",
    "#                 wc[p[0]] += 1\n",
    "#             else:\n",
    "#                 wc[p[0]] = 1\n",
    "#     for key in wc.keys():\n",
    "#         wcFile.write(key + '\\t' + str(wc[key]) + '\\n')\n",
    "#     print('词频结果保存成功')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "# from jieba import analyse\n",
    "\n",
    "# def tfidf_extract(text,keyword_num=10000):\n",
    "#     tfidf = analyse.extract_tags\n",
    "#     analyse.set_stop_words('stopword.txt')\n",
    "#     keywords = tfidf(text, keyword_num)\n",
    "#     # 输出抽取出的关键词\n",
    "#     for keyword in keywords:\n",
    "#         with open('data/segword/keywords2.txt','w', encoding='utf8') as f:\n",
    "#             for k in keywords:\n",
    "#                 f.write(str(k))\n",
    "#                 f.write('\\n')\n",
    "                \n",
    "# tfidf_extract(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2词术语搭配\n",
    "# import math\n",
    "# import re\n",
    "# first = 0\n",
    "# with open('data/segword/test.txt', 'w', encoding = 'utf-8') as cf:\n",
    "#     while first < len(ind_list)-1:\n",
    "#         second = first\n",
    "#         while second < len(ind_list)-1:\n",
    "#             # print(second)\n",
    "#             twoword = pvuv['words'][first] + pvuv['words'][second+1]\n",
    "#             # cf.write(twoword)\n",
    "#             # cf.write('\\n')\n",
    "#             count = len(re.findall(twoword,text))\n",
    "#             if count != 0:\n",
    "#                 with open('data/segword/wordoftxt.txt','w', encoding = 'utf-8') as wf:\n",
    "#                     wf.write(twoword)\n",
    "#                     wf.write('\\n')\n",
    "#                 print(twoword, count)\n",
    "#             second += 1\n",
    "#         first += 1   \n",
    "#             # twospeech = pvuv['speech'][first] + '+' + pvuv['speech'][second+1]\n",
    "# #             if twospeech == 'n+n':\n",
    "# #                 cf.write(twoword)\n",
    "# #                 cf.write('\\n')\n",
    "                \n",
    "# #             elif twospeech == 'n+v':\n",
    "# #                 cf.write(twoword)\n",
    "# #                 cf.write('\\n')\n",
    "                \n",
    "# #             elif twospeech == 'v+n':\n",
    "# #                 cf.write(twoword)\n",
    "# #                 cf.write('\\n')\n",
    "                \n",
    "# #             elif twospeech == 'a+n':\n",
    "# #                 cf.write(twoword)\n",
    "# #                 cf.write('\\n')\n",
    "                \n",
    "# #             elif twospeech == 'd+n':\n",
    "# #                 cf.write(twoword)\n",
    "# #                 cf.write('\\n')\n",
    "                \n",
    "# #             elif twospeech == 'b+n':\n",
    "# #                 cf.write(twoword)\n",
    "# #                 cf.write('\\n')\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 术语在文章中出现次数\n",
    "# import re\n",
    "# i = 0\n",
    "# count_lst = []\n",
    "# with open('data/segword/segcom.txt', 'r', encoding = 'utf-8') as countf:\n",
    "#     for line in countf:\n",
    "#         line = line.strip()\n",
    "#         count = len(re.findall(line,text))\n",
    "#         if count != 0:\n",
    "#             count_lst.append([line,count])\n",
    "#         # print(line + ' ' + str(count))\n",
    "#         # i+=1\n",
    "#     # print(count_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 分词 + 停用词筛选\n",
    "# import jpype\n",
    "# from pyhanlp import *\n",
    "# for pdf in pdfs:\n",
    "#     with open(pdf,'r',encoding='utf8') as f:\n",
    "#         with open('data/segword/segHan.txt','w', encoding='utf8') as segFile:\n",
    "#             for l in f:\n",
    "#                 l = l.strip()\n",
    "#                 reg = re.compile(\"[^\\u4e00-\\u9fa5]\")\n",
    "#                 l = re.sub(reg, '', l)\n",
    "#                 if l != '':\n",
    "#                     if l not in stopwords:\n",
    "#                         i = 0\n",
    "#                         for term in HanLP.segment(l):\n",
    "#                             segFile.write(str(i) + '\\t' + str(term.word) + '\\t' + str(term.nature))\n",
    "#                             segFile.write('\\n')\n",
    "#                             i += 1\n",
    "#         print('分词结果保存成功')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
